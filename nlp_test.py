# -*- coding: utf-8 -*-
"""nlp_test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fY5sXdId0MTnGvBGhnCb1mly6VFTHNKO
"""

import pandas as pd
from joblib import load
import json
from sklearn.metrics import f1_score
from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer
import os

# Load the trained model
model = load("random_forest_model.joblib")

# Load the test data and labels
x_test = pd.read_csv("x_test.csv", index_col=0)
y_test = pd.read_csv("y_test.csv", index_col=0)
x_train = pd.read_csv("x_train.csv", index_col=0)
y_train = pd.read_csv("y_train.csv", index_col=0)
# Initialize the CountVectorizer and TfidfTransformer
count_vect = CountVectorizer(stop_words='english')
transformer = TfidfTransformer(norm='l2', sublinear_tf=True)

x_train_counts = count_vect.fit_transform(x_train['text'])
x_train_tfidf = transformer.fit_transform(x_train_counts)

# Transform the test data using the fitted vectorizer and transformer
x_test_counts = count_vect.transform(x_test['text'])
x_test_tfidf = transformer.transform(x_test_counts)

# Make predictions using the trained model
predictions = model.predict(x_test_tfidf)

# Calculate the F1 score
f1_micro = f1_score(y_test, predictions, average='micro')

# Create a dictionary to store the test metadata
test_metadata = {
    'F1 Micro': f1_micro
}

# Define the directory where you want to save the results
RESULTS_DIR = ""  # Replace with your directory path

# Specify the name of the test results file
test_results_file = 'test_metadata.json'

# Create the full path to the results file
results_path = os.path.join(RESULTS_DIR, test_results_file)

# Serialize and save the metadata
with open(results_path, 'w') as outfile:
    json.dump(test_metadata, outfile)

